{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from glob import glob\n",
    "import random\n",
    "from conditionDiffusion.unet import ImprovedUnet\n",
    "from conditionDiffusion.utils import get_named_beta_schedule\n",
    "from conditionDiffusion.diffusion import GaussianDiffusion\n",
    "from conditionDiffusion.Scheduler import GradualWarmupScheduler\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\", 0)\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'image_size': 512,\n",
    "    'lr': 1e-5,           # ‚¨ÜÔ∏è 2e-5 ‚Üí 1e-4 (AMPÏôÄ Ìï®Íªò ÏÇ¨Ïö© Ïãú ÏïàÏ†ïÏ†Å)\n",
    "    'beta1': 0.9,\n",
    "    'beta2': 0.999,\n",
    "    'batch_size': 1,\n",
    "    'epochs': 1000,\n",
    "    'n_classes': None,\n",
    "    'image_count': 100,\n",
    "    'inch': 3,\n",
    "    'mask_ch': 3,\n",
    "    'modch': 64,\n",
    "    'outch': 3,\n",
    "    'chmul': [1, 2, 4, 8],\n",
    "    'numres': 2,\n",
    "    'dtype': torch.float32,\n",
    "    'cdim': 10,\n",
    "    'useconv': True,\n",
    "    'droprate': 0.1,\n",
    "    'T': 1000,\n",
    "    'w': 1.8,\n",
    "    'v': 0.3,\n",
    "    'multiplier': 1.0,\n",
    "    'threshold': 0.1,\n",
    "    'ddim': True,\n",
    "    'gen_n': 8,\n",
    "    'use_checkpoint': True,\n",
    "    'num_heads': 4,\n",
    "    'ema_decay': 0.9999,\n",
    "    'grad_clip': 1.0,      # ‚≠ê Gradient clipping Ï∂îÍ∞Ä\n",
    "    'warmup_epochs': 100,  # ‚≠ê Warmup Í∏∞Í∞Ñ Î™ÖÏãú\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "def transback(data):\n",
    "    return data / 2 + 0.5\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, params, images, mask):\n",
    "        self.images = images\n",
    "        self.masks = mask\n",
    "        self.args = params\n",
    "        \n",
    "    def trans(self, image, mask):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "            mask = transform(mask)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "            mask = transform(mask)\n",
    "        return image, mask\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        mask = self.masks[index]\n",
    "        image, mask = self.trans(image, mask)\n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "# Load data\n",
    "ihc_image_list = glob('../../data/IHC4BC_Compressed/**/HER2/IHC/*.jpg')\n",
    "image_temp_list = glob('../../data/IHC4BC_Compressed/**/Ki67/IHC/*.jpg')\n",
    "ihc_image_list.extend(image_temp_list)\n",
    "he_image_list = [p.replace('/IHC/', '/HE/') for p in ihc_image_list]\n",
    "\n",
    "if len(ihc_image_list) > params['image_count']:\n",
    "    ihc_image_list = ihc_image_list[:params['image_count']]\n",
    "    he_image_list = he_image_list[:params['image_count']]\n",
    "\n",
    "train_ihc_image = torch.zeros((len(ihc_image_list), params['inch'], \n",
    "                               params['image_size'], params['image_size']))\n",
    "train_he_image = torch.zeros((len(ihc_image_list), params['inch'], \n",
    "                              params['image_size'], params['image_size']))\n",
    "\n",
    "for i in tqdm(range(len(ihc_image_list))):\n",
    "    train_ihc_image[i] = trans(transforms.ToTensor()(\n",
    "        Image.open(ihc_image_list[i]).convert('RGB').resize(\n",
    "            (params['image_size'], params['image_size']))))\n",
    "    train_he_image[i] = trans(transforms.ToTensor()(\n",
    "        Image.open(he_image_list[i]).convert('RGB').resize(\n",
    "            (params['image_size'], params['image_size']))))\n",
    "    \n",
    "train_dataset = CustomDataset(params, train_ihc_image, train_he_image)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=params['batch_size'], \n",
    "                             num_workers=4, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ImprovedUnet(\n",
    "    in_ch=params['inch'] + params['mask_ch'],\n",
    "    mod_ch=params['modch'],\n",
    "    out_ch=params['outch'],\n",
    "    ch_mul=params['chmul'],\n",
    "    num_res_blocks=params['numres'],\n",
    "    cdim=params['cdim'],\n",
    "    use_conv=params['useconv'],\n",
    "    droprate=params['droprate'],\n",
    "    num_heads=params['num_heads'],\n",
    "    use_checkpoint=params['use_checkpoint'],\n",
    "    dtype=params['dtype']\n",
    ").to(device)\n",
    "\n",
    "betas = get_named_beta_schedule(num_diffusion_timesteps=params['T'])\n",
    "diffusion = GaussianDiffusion(\n",
    "    dtype=params['dtype'],\n",
    "    model=net,\n",
    "    betas=betas,\n",
    "    w=params['w'],\n",
    "    v=params['v'],\n",
    "    device=device\n",
    ")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    diffusion.model.parameters(),\n",
    "    lr=params['lr'],\n",
    "    betas=(params['beta1'], params['beta2']),\n",
    "    weight_decay=2e-5\n",
    ")\n",
    "\n",
    "# üîß ÏàòÏ†ï: Cosine Scheduler T_max ÏàòÏ†ï\n",
    "cosineScheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer=optimizer,\n",
    "    T_max=params['epochs'] - params['warmup_epochs'],  # ‚≠ê Ï†ÑÏ≤¥ epochsÏóêÏÑú warmup Ï†úÏô∏\n",
    "    eta_min=1e-6  # ‚≠ê ÏµúÏÜå lr ÏÑ§Ï†ï\n",
    ")\n",
    "\n",
    "warmUpScheduler = GradualWarmupScheduler(\n",
    "    optimizer=optimizer,\n",
    "    multiplier=params['multiplier'],\n",
    "    warm_epoch=params['warmup_epochs'],  # ‚≠ê Î™ÖÏãúÏ†ÅÏúºÎ°ú warmup Í∏∞Í∞Ñ ÏÑ§Ï†ï\n",
    "    after_scheduler=cosineScheduler,\n",
    "    last_epoch=0\n",
    ")\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "ema_model = deepcopy(diffusion.model)\n",
    "ema_model.eval()\n",
    "\n",
    "def update_ema(ema_model, model, decay=0.9999):\n",
    "    with torch.no_grad():\n",
    "        for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "            ema_param.data.mul_(decay).add_(param.data, alpha=1 - decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Gradient ÌÜµÍ≥Ñ Ï∂îÏ†Å\n",
    "grad_norm_history = []\n",
    "\n",
    "for epc in range(params['epochs']):\n",
    "    diffusion.model.train()\n",
    "    total_loss = 0\n",
    "    steps = 0\n",
    "    \n",
    "    with tqdm(train_dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "        for img, mask in tqdmDataLoader:\n",
    "            b = img.shape[0]\n",
    "            \n",
    "            cond_ihc = img.to(device)\n",
    "            x_0 = mask.to(device)\n",
    "            \n",
    "            # Classifier-free guidanceÏö© cemb\n",
    "            cemb = torch.zeros((b, params['cdim']), device=device)\n",
    "            \n",
    "            # Conditioning Ïù¥ÎØ∏ÏßÄ dropout\n",
    "            cond_input = cond_ihc.clone()\n",
    "            drop_idx = (torch.rand(b, device=device) < params['threshold'])\n",
    "            if drop_idx.any():\n",
    "                cond_input[drop_idx] = 0\n",
    "            \n",
    "            # üîß ÏàòÏ†ï: AMP ÏÇ¨Ïö© + Gradient Clipping\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss = diffusion.trainloss(x_0, mask=cond_input, cemb=cemb)\n",
    "                \n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # ‚≠ê Gradient Clipping (NaN Î∞©ÏßÄÏùò ÌïµÏã¨!)\n",
    "            scaler.unscale_(optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                diffusion.model.parameters(), \n",
    "                params['grad_clip']\n",
    "            )\n",
    "            grad_norm_history.append(grad_norm.item())\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # ‚≠ê EMA ÏóÖÎç∞Ïù¥Ìä∏\n",
    "            if steps % 10 == 0:  # 10 Ïä§ÌÖùÎßàÎã§ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                update_ema(ema_model, diffusion.model, params['ema_decay'])\n",
    "            \n",
    "            steps += 1\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            tqdmDataLoader.set_postfix(\n",
    "                ordered_dict={\n",
    "                    \"epoch\": epc + 1,\n",
    "                    \"loss\": f\"{total_loss / steps:.4f}\",\n",
    "                    \"grad_norm\": f\"{grad_norm.item():.4f}\",\n",
    "                    \"LR\": f\"{optimizer.state_dict()['param_groups'][0]['lr']:.2e}\",\n",
    "                    \"scale\": f\"{scaler.get_scale():.0f}\"\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    warmUpScheduler.step()\n",
    "    \n",
    "\n",
    "    original_model = diffusion.model\n",
    "    diffusion.model = ema_model\n",
    "    diffusion.model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        gen_n = min(params['gen_n'], train_ihc_image.shape[0])\n",
    "        cond_for_gen = train_ihc_image[:gen_n].to(device)\n",
    "        \n",
    "        # ‚≠ê ÏàòÏ†ï: cembÎ•º ÏÉùÏÑ± ÏãúÏóêÎèÑ Ïò¨Î∞îÎ•¥Í≤å ÏÉùÏÑ±\n",
    "        cemb_gen = torch.zeros((gen_n, params['cdim']), device=device)\n",
    "        \n",
    "        genshape = (gen_n, 3, params['image_size'], params['image_size'])\n",
    "        \n",
    "        if params['ddim']:\n",
    "            generated = diffusion.ddim_sample(\n",
    "                genshape, 50, 0.5, 'quadratic', \n",
    "                mask=cond_for_gen, cemb=cemb_gen\n",
    "            )\n",
    "        else:\n",
    "            generated = diffusion.sample(\n",
    "                genshape, \n",
    "                mask=cond_for_gen, cemb=cemb_gen\n",
    "            )\n",
    "        \n",
    "        # Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû•\n",
    "        generated = transback(generated)\n",
    "        cond_for_gen = transback(cond_for_gen)\n",
    "        \n",
    "        concatenated_images = torch.cat([\n",
    "            torch.cat([cond_for_gen[i].cpu(), generated[i].cpu()], dim=2) \n",
    "            for i in range(gen_n)\n",
    "        ], dim=1)\n",
    "        \n",
    "        img_pil = topilimage(concatenated_images)\n",
    "        createDirectory(f'../../results/IHC2HE/condition_diffusion/membrane')\n",
    "        img_pil.save(\n",
    "            f'../../results/IHC2HE/condition_diffusion/membrane/epc_{epc+1}_samples.png'\n",
    "        )\n",
    "    \n",
    "    # Î™®Îç∏ Î≥µÏõê\n",
    "    diffusion.model = original_model\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epc + 1,\n",
    "        'net': diffusion.model.state_dict(),\n",
    "        'ema_net': ema_model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': warmUpScheduler.state_dict(),\n",
    "        'scaler': scaler.state_dict(),\n",
    "        'params': params\n",
    "    }\n",
    "    createDirectory(f'../../model/IHC2HE/condition_diffusion/membrane/')\n",
    "    torch.save(\n",
    "        checkpoint, \n",
    "        f'../../model/IHC2HE/condition_diffusion/membrane/ckpt_{epc+1}.pt'\n",
    "    )\n",
    "    print(f\"\\nüíæ Checkpoint saved at epoch {epc+1}\")\n",
    "\n",
    "print(\"‚úÖ Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
