{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import get_rank, init_process_group, destroy_process_group, all_gather, get_world_size\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from conditionDiffusion.unet import Unet\n",
    "from conditionDiffusion.utils import get_named_beta_schedule\n",
    "# Note: using channel-concat IHC conditioning (IHC image -> condition); no label-based ConditionalEmbedding used here.\n",
    "from conditionDiffusion.diffusion import GaussianDiffusion\n",
    "from conditionDiffusion.Scheduler import GradualWarmupScheduler\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",0)\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "def createDirectory(directory):\n",
    "    \"\"\"_summary_\n",
    "        create Directory\n",
    "    Args:\n",
    "        directory (string): file_path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'image_size':512,\n",
    "        'lr':2e-5,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':1,\n",
    "        'epochs':1000,\n",
    "        'n_classes':None,\n",
    "        'image_count':15000,\n",
    "        'inch':3,\n",
    "        'mask_ch': 3,  # number of channels in conditioning IHC images (default same as image channels)\n",
    "        'modch':128,\n",
    "        'outch':3,\n",
    "        'chmul':[1,2,4,8],\n",
    "        'numres':1,\n",
    "        'dtype':torch.float32,\n",
    "        'cdim':10,\n",
    "        'useconv':False,\n",
    "        'droprate':0.1,\n",
    "        'T':1000,\n",
    "        'w':1.8,\n",
    "        'v':0.3,\n",
    "        'multiplier':1,\n",
    "        'threshold':0.1,\n",
    "        'ddim':True,\n",
    "        'gen_n':8,  # number of IHC exemplars to sample for generation\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "def transback(data:Tensor) -> Tensor:\n",
    "    return data / 2 + 0.5\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"IHC->HE paired dataset.\n",
    "\n",
    "    Returns (ihc_image, he_image, label) for each index.\n",
    "    \"\"\"\n",
    "    def __init__(self,parmas, images,mask):\n",
    "        \n",
    "        self.images = images\n",
    "        self.masks = mask\n",
    "        self.args=parmas\n",
    "      \n",
    "        \n",
    "    def trans(self,image,mask):\n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomHorizontalFlip(1)\n",
    "            image = transform(image)\n",
    "            mask = transform(mask)\n",
    "            \n",
    "        if random.random() > 0.5:\n",
    "            transform = transforms.RandomVerticalFlip(1)\n",
    "            image = transform(image)\n",
    "            mask = transform(mask)\n",
    "        return image,mask\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image=self.images[index]\n",
    "\n",
    "        mask=self.masks[index]\n",
    "        image,mask = self.trans(image,mask)\n",
    "        return image,mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "image_path=[]\n",
    "ihc_image_list=glob('../../data/IHC4BC_Compressed/**/HER2/IHC/*.jpg')\n",
    "image_temp_list=glob('../../data/IHC4BC_Compressed/**/Ki67/IHC/*.jpg')\n",
    "ihc_image_list.extend(image_temp_list)\n",
    "random.shuffle(ihc_image_list)\n",
    "he_image_list=[p.replace('/IHC/','/HE/') for p in ihc_image_list]\n",
    "if len(ihc_image_list)>params['image_count']:\n",
    "    ihc_image_list=ihc_image_list[:params['image_count']]\n",
    "    he_image_list=he_image_list[:params['image_count']]\n",
    "\n",
    "train_ihc_image=torch.zeros((len(ihc_image_list),params['inch'],params['image_size'],params['image_size']))\n",
    "train_he_image=torch.zeros((len(ihc_image_list),params['inch'],params['image_size'],params['image_size']))\n",
    "\n",
    "for i in tqdm(range(len(ihc_image_list))):\n",
    "    train_ihc_image[i]=trans(transforms.ToTensor()(Image.open(ihc_image_list[i]).convert('RGB').resize((params['image_size'],params['image_size']))))\n",
    "    train_he_image[i]=trans(transforms.ToTensor()(Image.open(he_image_list[i]).convert('RGB').resize((params['image_size'],params['image_size']))))\n",
    "    \n",
    "train_dataset=CustomDataset(params,train_ihc_image,train_he_image)\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=params['batch_size'],num_workers=4,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# 리스트 순서 섞기\n",
    "random.shuffle(my_list)\n",
    "\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(in_ch = params['inch'] + params['mask_ch'],\n",
    "            mod_ch = params['modch'],\n",
    "            out_ch = params['outch'],\n",
    "            ch_mul = params['chmul'],\n",
    "            num_res_blocks = params['numres'],\n",
    "            cdim = params['cdim'],\n",
    "            use_conv = params['useconv'],\n",
    "            droprate = params['droprate'],\n",
    "            dtype = params['dtype']\n",
    "            ).to(device)\n",
    "# We will sample conditioning IHC images from `train_ihc_image` at generation time (no persistent cond tensor list needed).\n",
    "betas = get_named_beta_schedule(num_diffusion_timesteps = params['T'])\n",
    "diffusion = GaussianDiffusion(\n",
    "                    dtype = params['dtype'],\n",
    "                    model = net,\n",
    "                    betas = betas,\n",
    "                    w = params['w'],\n",
    "                    v = params['v'],\n",
    "                    device = device\n",
    "                )\n",
    "optimizer = torch.optim.AdamW(\n",
    "                diffusion.model.parameters(),\n",
    "                lr = params['lr'],\n",
    "                weight_decay = 1e-4\n",
    "            )\n",
    "\n",
    "\n",
    "cosineScheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                            optimizer = optimizer,\n",
    "                            T_max = params['epochs']/100,\n",
    "                            eta_min = 0,\n",
    "                            last_epoch = -1\n",
    "                        )\n",
    "warmUpScheduler = GradualWarmupScheduler(\n",
    "                        optimizer = optimizer,\n",
    "                        multiplier = params['multiplier'],\n",
    "                        warm_epoch = params['epochs'] // 10,\n",
    "                        after_scheduler = cosineScheduler,\n",
    "                        last_epoch = 0\n",
    "                    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epc in range(params['epochs']):\n",
    "    diffusion.model.train()\n",
    "    total_loss = 0\n",
    "    steps = 0\n",
    "    with tqdm(train_dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "        for img, mask in tqdmDataLoader:\n",
    "            b = img.shape[0]\n",
    "\n",
    "            # For image-translation: img = IHC (condition), mask = HE (target)\n",
    "            cond_ihc = img.to(device)\n",
    "            x_0 = mask.to(device)\n",
    "\n",
    "            # Channel-concat conditioning: prepare cond and zero global cemb\n",
    "            cond_input = cond_ihc.clone()\n",
    "            drop_idx = (torch.rand(b, device=device) < params['threshold'])\n",
    "            if drop_idx.any():\n",
    "                cond_input[drop_idx] = 0\n",
    "\n",
    "            # AMP를 사용한 손실 계산 및 역전파\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss = diffusion.trainloss(x_0, mask=cond_input)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            steps += 1\n",
    "            total_loss += loss.item()\n",
    "            tqdmDataLoader.set_postfix(\n",
    "                ordered_dict={\n",
    "                    \"epoch\": epc + 1,\n",
    "                    \"loss\": total_loss / steps,\n",
    "                    \"batch per device\": x_0.shape[0],\n",
    "                    \"img shape\": x_0.shape[1:],\n",
    "                    \"LR\": optimizer.state_dict()['param_groups'][0][\"lr\"]\n",
    "                }\n",
    "            )\n",
    "\n",
    "    warmUpScheduler.step()\n",
    "    diffusion.model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Select conditioning exemplars from train_ihc_image (first params['gen_n'] or whole if smaller)\n",
    "        try:\n",
    "            gen_n = min(params['gen_n'], train_ihc_image.shape[0])\n",
    "            cond_for_gen = train_ihc_image[:gen_n].to(device)\n",
    "        except NameError:\n",
    "            # If train_ihc_image isn't available, fallback to a random noise cond of appropriate channels\n",
    "            cond_for_gen = torch.randn((params['gen_n'], params['mask_ch'], params['image_size'], params['image_size']), device=device)\n",
    "\n",
    "        # Define generation shape for the image batches\n",
    "        genshape = (cond_for_gen.shape[0], 3, params['image_size'], params['image_size'])\n",
    "        # Sample images using the chosen method (DDIM or standard sampling)\n",
    "        if params['ddim']:\n",
    "            generated = diffusion.ddim_sample(genshape, 50, 0.5, 'quadratic', mask=cond_for_gen)\n",
    "        else:\n",
    "            generated = diffusion.sample(genshape, mask=cond_for_gen)\n",
    "\n",
    "        # Convert the generated tensors to images and save them as a single concatenated image\n",
    "        generated = transback(generated.to(device))\n",
    "        concatenated_images = torch.cat([torch.concat([cond_for_gen[i].cpu() / 2. + 0.5, generated[i].cpu() / 2. + 0.5], dim=2) for i in range(cond_for_gen.shape[0])], dim=1)\n",
    "        img_pil = topilimage(concatenated_images)\n",
    "        createDirectory(f'../../results/IHC2HE/condition_diffusion/membrain')\n",
    "        img_pil.save(f'../../results/IHC2HE/condition_diffusion/membrain/epc_{epc}_all_samples.png')\n",
    "\n",
    "        # Save model checkpoint (no cemblayer state needed)\n",
    "        checkpoint = {\n",
    "            'net': diffusion.model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': warmUpScheduler.state_dict()\n",
    "        }\n",
    "        createDirectory(f'../../model/IHC2HE/condition_diffusion/membrain/')\n",
    "        torch.save(checkpoint, f'../../model/IHC2HE/condition_diffusion/membrain/ckpt_{epc+1}_checkpoint.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
